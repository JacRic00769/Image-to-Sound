# Image-to-Sound: Algorithmic Music from Visual Data ğŸ¼ğŸ–¼ï¸

This project explores the creative intersection of computer vision and music composition by converting image pixel data into algorithmically generated sound. Developed during an Independent Summer Research Grant in 2024, the goal was to translate raw visual information into meaningful sonic output using a combination of programming and audio tools.

## ğŸ” Project Overview

The system analyzes static image data and maps it to musical elements such as:
- **Pitch**
- **Rhythm**
- **Timbre**
- **Amplitude**

By using tools like **Python**, **Java**, and **Max/MSP**, the project bridges the gap between image processing and algorithmic composition. Additional sound design and arrangement were handled using **Ableton Live**.

## ğŸ› ï¸ Tools and Technologies

- **Python** â€“ For image analysis and data extraction.
- **Java** â€“ For data handling and possible MIDI/sound manipulation.
- **Max/MSP** â€“ For real-time sound generation and interactive audio processing.
- **Ableton Live** â€“ For post-processing, layering, and mastering.
- **JPG/PNG images** â€“ Used as the base input material.

## ğŸ“‚ Repository Structure

